[2018-04-19T08:48:35,476][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/home/kurt/migrations/jdbc-importer/logstash/logstash-5.6.0/modules/netflow/configuration"}
[2018-04-19T08:48:35,487][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/home/kurt/migrations/jdbc-importer/logstash/logstash-5.6.0/modules/fb_apache/configuration"}
[2018-04-19T08:48:36,034][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://localhost:9200/]}}
[2018-04-19T08:48:36,041][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://localhost:9200/, :path=>"/"}
[2018-04-19T08:48:36,160][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://localhost:9200/"}
[2018-04-19T08:48:36,161][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-04-19T08:48:36,204][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-04-19T08:48:36,212][INFO ][logstash.outputs.elasticsearch] Installing elasticsearch template to _template/logstash
[2018-04-19T08:48:36,283][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//localhost:9200"]}
[2018-04-19T08:48:36,286][INFO ][logstash.pipeline        ] Starting pipeline {"id"=>"main", "pipeline.workers"=>4, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>5, "pipeline.max_inflight"=>500}
[2018-04-19T08:48:36,399][INFO ][logstash.pipeline        ] Pipeline main started
[2018-04-19T08:48:36,473][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2018-04-19T08:48:37,087][INFO ][logstash.inputs.jdbc     ] (0.024000s) SELECT count(*) AS `count` FROM (SELECT `campaign`.`is_in_trash`, `campaign`.`id`, `campaign`.`message`, `campaign`.`name`, `campaign`.`campaign_status_id`, `campaign`.`keyword_id`, `campaign`.`is_valid`, `creator_user`.fname creator_fname, `creator_user`.mname creator_mname, `creator_user`.lname creator_lname, `updater_user`.fname updater_fname, `updater_user`.mname updater_mname, `updater_user`.lname updater_lname, `campaign`.date_created, `campaign`.date_completed, `campaign`.account_id, `campaign`.`campaign_type_id`, `campaign_type`.name campaign_type, `campaign_status`.name campaign_status_name FROM (`campaign`) LEFT OUTER JOIN `user` creator_user ON `creator_user`.`id` = `campaign`.`created_by_id` LEFT OUTER JOIN `user` updater_user ON `updater_user`.`id` = `campaign`.`updated_by_id` LEFT OUTER JOIN `campaign_type` campaign_type ON `campaign_type`.`id` = `campaign`.`campaign_type_id` LEFT OUTER JOIN `campaign_status` campaign_status ON `campaign_status`.`id` = `campaign`.`campaign_status_id`) AS `t1` LIMIT 1
[2018-04-19T08:48:37,128][INFO ][logstash.inputs.jdbc     ] (0.037000s) SELECT * FROM (SELECT `campaign`.`is_in_trash`, `campaign`.`id`, `campaign`.`message`, `campaign`.`name`, `campaign`.`campaign_status_id`, `campaign`.`keyword_id`, `campaign`.`is_valid`, `creator_user`.fname creator_fname, `creator_user`.mname creator_mname, `creator_user`.lname creator_lname, `updater_user`.fname updater_fname, `updater_user`.mname updater_mname, `updater_user`.lname updater_lname, `campaign`.date_created, `campaign`.date_completed, `campaign`.account_id, `campaign`.`campaign_type_id`, `campaign_type`.name campaign_type, `campaign_status`.name campaign_status_name FROM (`campaign`) LEFT OUTER JOIN `user` creator_user ON `creator_user`.`id` = `campaign`.`created_by_id` LEFT OUTER JOIN `user` updater_user ON `updater_user`.`id` = `campaign`.`updated_by_id` LEFT OUTER JOIN `campaign_type` campaign_type ON `campaign_type`.`id` = `campaign`.`campaign_type_id` LEFT OUTER JOIN `campaign_status` campaign_status ON `campaign_status`.`id` = `campaign`.`campaign_status_id`) AS `t1` LIMIT 100000 OFFSET 0
[2018-04-19T08:48:40,919][WARN ][logstash.agent           ] stopping pipeline {:id=>"main"}
[2018-04-19T08:49:10,980][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/home/kurt/migrations/jdbc-importer/logstash/logstash-5.6.0/modules/netflow/configuration"}
[2018-04-19T08:49:10,983][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/home/kurt/migrations/jdbc-importer/logstash/logstash-5.6.0/modules/fb_apache/configuration"}
[2018-04-19T08:49:11,479][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://localhost:9200/]}}
[2018-04-19T08:49:11,481][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://localhost:9200/, :path=>"/"}
[2018-04-19T08:49:11,573][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://localhost:9200/"}
[2018-04-19T08:49:11,574][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-04-19T08:49:11,607][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-04-19T08:49:11,619][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//localhost:9200"]}
[2018-04-19T08:49:11,620][INFO ][logstash.pipeline        ] Starting pipeline {"id"=>"main", "pipeline.workers"=>4, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>5, "pipeline.max_inflight"=>500}
[2018-04-19T08:49:11,718][INFO ][logstash.pipeline        ] Pipeline main started
[2018-04-19T08:49:11,759][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2018-04-19T08:49:12,346][INFO ][logstash.inputs.jdbc     ] (0.098000s) SELECT count(*) AS `count` FROM (SELECT api_mt_send_q.id api_mt_send_q_id, api_mt.id api_mt_id, api_mt.is_valid is_valid, api_mt.date_created, api_mt.is_priority, api_mt.message, api_mt_send_q.mobile, api_mt.account_id, api_mt.keyword_id, api_mt.sms_inbound_id, user.fname, user.mname, user.lname, type.id type_id, type.name type_name, dlr_status.name dlr_status_name, send_status.name send_status_name, api_mt.is_in_trash is_in_trash FROM api_mt api_mt LEFT OUTER JOIN user user ON user.id = api_mt.user_id LEFT OUTER JOIN type type ON type.id = api_mt.type_id LEFT OUTER JOIN api_mt_send_q api_mt_send_q ON api_mt_send_q.api_mt_id = api_mt.id LEFT OUTER JOIN dlr_status dlr_status ON dlr_status.id = api_mt_send_q.dlr_status_id LEFT OUTER JOIN send_status send_status ON send_status.id = api_mt_send_q.send_status_id WHERE api_mt.is_in_trash=0 OR api_mt.is_in_trash IS NULL) AS `t1` LIMIT 1
[2018-04-19T08:49:12,436][INFO ][logstash.inputs.jdbc     ] (0.086000s) SELECT * FROM (SELECT api_mt_send_q.id api_mt_send_q_id, api_mt.id api_mt_id, api_mt.is_valid is_valid, api_mt.date_created, api_mt.is_priority, api_mt.message, api_mt_send_q.mobile, api_mt.account_id, api_mt.keyword_id, api_mt.sms_inbound_id, user.fname, user.mname, user.lname, type.id type_id, type.name type_name, dlr_status.name dlr_status_name, send_status.name send_status_name, api_mt.is_in_trash is_in_trash FROM api_mt api_mt LEFT OUTER JOIN user user ON user.id = api_mt.user_id LEFT OUTER JOIN type type ON type.id = api_mt.type_id LEFT OUTER JOIN api_mt_send_q api_mt_send_q ON api_mt_send_q.api_mt_id = api_mt.id LEFT OUTER JOIN dlr_status dlr_status ON dlr_status.id = api_mt_send_q.dlr_status_id LEFT OUTER JOIN send_status send_status ON send_status.id = api_mt_send_q.send_status_id WHERE api_mt.is_in_trash=0 OR api_mt.is_in_trash IS NULL) AS `t1` LIMIT 100000 OFFSET 0
[2018-04-19T08:49:18,757][WARN ][logstash.agent           ] stopping pipeline {:id=>"main"}
[2018-04-19T08:49:51,594][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/home/kurt/migrations/jdbc-importer/logstash/logstash-5.6.0/modules/netflow/configuration"}
[2018-04-19T08:49:51,600][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/home/kurt/migrations/jdbc-importer/logstash/logstash-5.6.0/modules/fb_apache/configuration"}
[2018-04-19T08:49:52,140][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://localhost:9200/]}}
[2018-04-19T08:49:52,142][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://localhost:9200/, :path=>"/"}
[2018-04-19T08:49:52,241][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://localhost:9200/"}
[2018-04-19T08:49:52,241][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-04-19T08:49:52,287][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-04-19T08:49:52,293][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//localhost:9200"]}
[2018-04-19T08:49:52,295][INFO ][logstash.pipeline        ] Starting pipeline {"id"=>"main", "pipeline.workers"=>4, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>5, "pipeline.max_inflight"=>500}
[2018-04-19T08:49:52,409][INFO ][logstash.pipeline        ] Pipeline main started
[2018-04-19T08:49:52,463][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2018-04-19T08:49:53,080][INFO ][logstash.inputs.jdbc     ] (0.114000s) SELECT count(*) AS `count` FROM (SELECT message_folders_message_folder.folder_id as folder_id, sms_inbound.contact_id as contact_id, sms_inbound.account_id as account_id, sms_inbound.keyword_id as keyword_id, sms_inbound.campaign_id as campaign_id,sms_inbound.id, sms_inbound.mobile, sms_inbound.message, sms_inbound.date_created, sms_inbound.senderid_name, sms_inbound.is_new, sms_inbound.date_last_updated, contact.first_name AS contact_first_name, contact.last_name AS contact_last_name FROM (sms_inbound) LEFT OUTER JOIN contact contact ON contact.id = sms_inbound.contact_id LEFT OUTER JOIN message_folder message_folders_message_folder ON sms_inbound.id = message_folders_message_folder.inbound_id WHERE IFNULL(is_in_trash, 0) <> 1) AS `t1` LIMIT 1
[2018-04-19T08:49:53,179][INFO ][logstash.inputs.jdbc     ] (0.096000s) SELECT * FROM (SELECT message_folders_message_folder.folder_id as folder_id, sms_inbound.contact_id as contact_id, sms_inbound.account_id as account_id, sms_inbound.keyword_id as keyword_id, sms_inbound.campaign_id as campaign_id,sms_inbound.id, sms_inbound.mobile, sms_inbound.message, sms_inbound.date_created, sms_inbound.senderid_name, sms_inbound.is_new, sms_inbound.date_last_updated, contact.first_name AS contact_first_name, contact.last_name AS contact_last_name FROM (sms_inbound) LEFT OUTER JOIN contact contact ON contact.id = sms_inbound.contact_id LEFT OUTER JOIN message_folder message_folders_message_folder ON sms_inbound.id = message_folders_message_folder.inbound_id WHERE IFNULL(is_in_trash, 0) <> 1) AS `t1` LIMIT 100000 OFFSET 0
[2018-04-19T08:50:01,456][WARN ][logstash.agent           ] stopping pipeline {:id=>"main"}
[2018-04-19T09:08:42,660][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/home/kurt/migrations/jdbc-importer/logstash/logstash-5.6.0/modules/netflow/configuration"}
[2018-04-19T09:08:42,664][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/home/kurt/migrations/jdbc-importer/logstash/logstash-5.6.0/modules/fb_apache/configuration"}
[2018-04-19T09:08:42,983][ERROR][logstash.plugins.registry] Problems loading a plugin with {:type=>"filter", :name=>"aggregate", :path=>"logstash/filters/aggregate", :error_message=>"NameError", :error_class=>NameError, :error_backtrace=>["/home/kurt/migrations/jdbc-importer/logstash/logstash-5.6.0/logstash-core/lib/logstash/plugins/registry.rb:226:in `namespace_lookup'", "/home/kurt/migrations/jdbc-importer/logstash/logstash-5.6.0/logstash-core/lib/logstash/plugins/registry.rb:162:in `legacy_lookup'", "/home/kurt/migrations/jdbc-importer/logstash/logstash-5.6.0/logstash-core/lib/logstash/plugins/registry.rb:138:in `lookup'", "/home/kurt/migrations/jdbc-importer/logstash/logstash-5.6.0/logstash-core/lib/logstash/plugins/registry.rb:180:in `lookup_pipeline_plugin'", "/home/kurt/migrations/jdbc-importer/logstash/logstash-5.6.0/logstash-core/lib/logstash/plugin.rb:140:in `lookup'", "/home/kurt/migrations/jdbc-importer/logstash/logstash-5.6.0/logstash-core/lib/logstash/pipeline.rb:103:in `plugin'", "(eval):12:in `initialize'", "org/jruby/RubyKernel.java:1079:in `eval'", "/home/kurt/migrations/jdbc-importer/logstash/logstash-5.6.0/logstash-core/lib/logstash/pipeline.rb:75:in `initialize'", "/home/kurt/migrations/jdbc-importer/logstash/logstash-5.6.0/logstash-core/lib/logstash/pipeline.rb:165:in `initialize'", "/home/kurt/migrations/jdbc-importer/logstash/logstash-5.6.0/logstash-core/lib/logstash/agent.rb:286:in `create_pipeline'", "/home/kurt/migrations/jdbc-importer/logstash/logstash-5.6.0/logstash-core/lib/logstash/agent.rb:95:in `register_pipeline'", "/home/kurt/migrations/jdbc-importer/logstash/logstash-5.6.0/logstash-core/lib/logstash/runner.rb:309:in `execute'", "/home/kurt/migrations/jdbc-importer/logstash/logstash-5.6.0/vendor/bundle/jruby/1.9/gems/clamp-0.6.5/lib/clamp/command.rb:67:in `run'", "/home/kurt/migrations/jdbc-importer/logstash/logstash-5.6.0/logstash-core/lib/logstash/runner.rb:204:in `run'", "/home/kurt/migrations/jdbc-importer/logstash/logstash-5.6.0/vendor/bundle/jruby/1.9/gems/clamp-0.6.5/lib/clamp/command.rb:132:in `run'", "/home/kurt/migrations/jdbc-importer/logstash/logstash-5.6.0/lib/bootstrap/environment.rb:71:in `(root)'"]}
[2018-04-19T09:08:43,015][ERROR][logstash.agent           ] Cannot create pipeline {:reason=>"Couldn't find any filter plugin named 'aggregate'. Are you sure this is correct? Trying to load the aggregate filter plugin resulted in this error: Problems loading the requested plugin named aggregate of type filter. Error: NameError NameError"}

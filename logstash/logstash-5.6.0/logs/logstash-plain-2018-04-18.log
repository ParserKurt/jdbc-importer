[2018-04-18T10:33:35,495][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/home/kurt/migrations/jdbc-importer/logstash/logstash-5.6.0/modules/netflow/configuration"}
[2018-04-18T10:33:35,507][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/home/kurt/migrations/jdbc-importer/logstash/logstash-5.6.0/modules/fb_apache/configuration"}
[2018-04-18T10:33:36,085][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://localhost:9200/]}}
[2018-04-18T10:33:36,086][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://localhost:9200/, :path=>"/"}
[2018-04-18T10:33:36,188][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://localhost:9200/"}
[2018-04-18T10:33:36,190][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-04-18T10:33:36,236][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-04-18T10:33:36,246][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//localhost:9200"]}
[2018-04-18T10:33:36,247][INFO ][logstash.pipeline        ] Starting pipeline {"id"=>"main", "pipeline.workers"=>4, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>5, "pipeline.max_inflight"=>500}
[2018-04-18T10:33:36,379][INFO ][logstash.pipeline        ] Pipeline main started
[2018-04-18T10:33:36,447][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2018-04-18T10:33:36,945][INFO ][logstash.inputs.jdbc     ] (0.028000s) SELECT count(*) AS `count` FROM (SELECT `campaign`.`is_in_trash`, `campaign`.`id`, `campaign`.`message`, `campaign`.`name`, `campaign`.`campaign_status_id`, `campaign`.`keyword_id`, `campaign`.`is_valid`, `creator_user`.fname creator_fname, `creator_user`.mname creator_mname, `creator_user`.lname creator_lname, `updater_user`.fname updater_fname, `updater_user`.mname updater_mname, `updater_user`.lname updater_lname, `campaign`.date_created, `campaign`.date_completed, `campaign`.account_id, `campaign`.`campaign_type_id`, `campaign_type`.name campaign_type, `campaign_status`.name campaign_status_name FROM (`campaign`) LEFT OUTER JOIN `user` creator_user ON `creator_user`.`id` = `campaign`.`created_by_id` LEFT OUTER JOIN `user` updater_user ON `updater_user`.`id` = `campaign`.`updated_by_id` LEFT OUTER JOIN `campaign_type` campaign_type ON `campaign_type`.`id` = `campaign`.`campaign_type_id` LEFT OUTER JOIN `campaign_status` campaign_status ON `campaign_status`.`id` = `campaign`.`campaign_status_id`) AS `t1` LIMIT 1
[2018-04-18T10:33:36,973][INFO ][logstash.inputs.jdbc     ] (0.025000s) SELECT * FROM (SELECT `campaign`.`is_in_trash`, `campaign`.`id`, `campaign`.`message`, `campaign`.`name`, `campaign`.`campaign_status_id`, `campaign`.`keyword_id`, `campaign`.`is_valid`, `creator_user`.fname creator_fname, `creator_user`.mname creator_mname, `creator_user`.lname creator_lname, `updater_user`.fname updater_fname, `updater_user`.mname updater_mname, `updater_user`.lname updater_lname, `campaign`.date_created, `campaign`.date_completed, `campaign`.account_id, `campaign`.`campaign_type_id`, `campaign_type`.name campaign_type, `campaign_status`.name campaign_status_name FROM (`campaign`) LEFT OUTER JOIN `user` creator_user ON `creator_user`.`id` = `campaign`.`created_by_id` LEFT OUTER JOIN `user` updater_user ON `updater_user`.`id` = `campaign`.`updated_by_id` LEFT OUTER JOIN `campaign_type` campaign_type ON `campaign_type`.`id` = `campaign`.`campaign_type_id` LEFT OUTER JOIN `campaign_status` campaign_status ON `campaign_status`.`id` = `campaign`.`campaign_status_id`) AS `t1` LIMIT 100000 OFFSET 0
[2018-04-18T10:33:40,421][WARN ][logstash.agent           ] stopping pipeline {:id=>"main"}
[2018-04-18T10:42:23,910][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/home/kurt/migrations/jdbc-importer/logstash/logstash-5.6.0/modules/netflow/configuration"}
[2018-04-18T10:42:23,915][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/home/kurt/migrations/jdbc-importer/logstash/logstash-5.6.0/modules/fb_apache/configuration"}
[2018-04-18T10:42:24,609][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://localhost:9200/]}}
[2018-04-18T10:42:24,611][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://localhost:9200/, :path=>"/"}
[2018-04-18T10:42:24,710][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://localhost:9200/"}
[2018-04-18T10:42:24,711][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-04-18T10:42:24,757][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-04-18T10:42:24,763][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//localhost:9200"]}
[2018-04-18T10:42:24,764][INFO ][logstash.pipeline        ] Starting pipeline {"id"=>"main", "pipeline.workers"=>4, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>5, "pipeline.max_inflight"=>500}
[2018-04-18T10:42:24,907][INFO ][logstash.pipeline        ] Pipeline main started
[2018-04-18T10:42:24,994][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2018-04-18T10:42:25,576][INFO ][logstash.inputs.jdbc     ] (0.107000s) SELECT count(*) AS `count` FROM (SELECT api_mt.id api_mt_id, api_mt.is_valid is_valid, api_mt.date_created, api_mt.is_priority, api_mt.message, api_mt.mobile, api_mt.account_id, api_mt.keyword_id, api_mt.sms_inbound_id, user.fname, user.mname, user.lname, type.id type_id, type.name type_name, dlr_status.name dlr_status_name, send_status.name send_status_name, api_mt.is_in_trash is_in_trash FROM api_mt api_mt LEFT OUTER JOIN user user ON user.id = api_mt.user_id LEFT OUTER JOIN type type ON type.id = api_mt.type_id LEFT OUTER JOIN api_mt_send_q api_mt_send_q ON api_mt_send_q.api_mt_id = api_mt.id LEFT OUTER JOIN dlr_status dlr_status ON dlr_status.id = api_mt_send_q.dlr_status_id LEFT OUTER JOIN send_status send_status ON send_status.id = api_mt_send_q.send_status_id WHERE api_mt.is_in_trash=0 OR api_mt.is_in_trash IS NULL) AS `t1` LIMIT 1
[2018-04-18T10:42:25,685][INFO ][logstash.inputs.jdbc     ] (0.103000s) SELECT * FROM (SELECT api_mt.id api_mt_id, api_mt.is_valid is_valid, api_mt.date_created, api_mt.is_priority, api_mt.message, api_mt.mobile, api_mt.account_id, api_mt.keyword_id, api_mt.sms_inbound_id, user.fname, user.mname, user.lname, type.id type_id, type.name type_name, dlr_status.name dlr_status_name, send_status.name send_status_name, api_mt.is_in_trash is_in_trash FROM api_mt api_mt LEFT OUTER JOIN user user ON user.id = api_mt.user_id LEFT OUTER JOIN type type ON type.id = api_mt.type_id LEFT OUTER JOIN api_mt_send_q api_mt_send_q ON api_mt_send_q.api_mt_id = api_mt.id LEFT OUTER JOIN dlr_status dlr_status ON dlr_status.id = api_mt_send_q.dlr_status_id LEFT OUTER JOIN send_status send_status ON send_status.id = api_mt_send_q.send_status_id WHERE api_mt.is_in_trash=0 OR api_mt.is_in_trash IS NULL) AS `t1` LIMIT 100000 OFFSET 0
[2018-04-18T10:42:32,537][WARN ][logstash.agent           ] stopping pipeline {:id=>"main"}
[2018-04-18T10:59:11,974][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/home/kurt/migrations/jdbc-importer/logstash/logstash-5.6.0/modules/netflow/configuration"}
[2018-04-18T10:59:11,978][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/home/kurt/migrations/jdbc-importer/logstash/logstash-5.6.0/modules/fb_apache/configuration"}
[2018-04-18T10:59:12,507][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://localhost:9200/]}}
[2018-04-18T10:59:12,509][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://localhost:9200/, :path=>"/"}
[2018-04-18T10:59:12,597][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://localhost:9200/"}
[2018-04-18T10:59:12,602][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-04-18T10:59:12,648][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-04-18T10:59:12,654][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//localhost:9200"]}
[2018-04-18T10:59:12,656][INFO ][logstash.pipeline        ] Starting pipeline {"id"=>"main", "pipeline.workers"=>4, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>5, "pipeline.max_inflight"=>500}
[2018-04-18T10:59:12,770][INFO ][logstash.pipeline        ] Pipeline main started
[2018-04-18T10:59:12,853][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2018-04-18T10:59:13,503][INFO ][logstash.inputs.jdbc     ] (0.098000s) SELECT count(*) AS `count` FROM (SELECT api_mt_send_q.id api_mt_send_q_id, api_mt.id api_mt_id, api_mt.is_valid is_valid, api_mt.date_created, api_mt.is_priority, api_mt.message, api_mt.mobile, api_mt.account_id, api_mt.keyword_id, api_mt.sms_inbound_id, user.fname, user.mname, user.lname, type.id type_id, type.name type_name, dlr_status.name dlr_status_name, send_status.name send_status_name, api_mt.is_in_trash is_in_trash FROM api_mt api_mt LEFT OUTER JOIN user user ON user.id = api_mt.user_id LEFT OUTER JOIN type type ON type.id = api_mt.type_id LEFT OUTER JOIN api_mt_send_q api_mt_send_q ON api_mt_send_q.api_mt_id = api_mt.id LEFT OUTER JOIN dlr_status dlr_status ON dlr_status.id = api_mt_send_q.dlr_status_id LEFT OUTER JOIN send_status send_status ON send_status.id = api_mt_send_q.send_status_id WHERE api_mt.is_in_trash=0 OR api_mt.is_in_trash IS NULL) AS `t1` LIMIT 1
[2018-04-18T10:59:13,627][INFO ][logstash.inputs.jdbc     ] (0.120000s) SELECT * FROM (SELECT api_mt_send_q.id api_mt_send_q_id, api_mt.id api_mt_id, api_mt.is_valid is_valid, api_mt.date_created, api_mt.is_priority, api_mt.message, api_mt.mobile, api_mt.account_id, api_mt.keyword_id, api_mt.sms_inbound_id, user.fname, user.mname, user.lname, type.id type_id, type.name type_name, dlr_status.name dlr_status_name, send_status.name send_status_name, api_mt.is_in_trash is_in_trash FROM api_mt api_mt LEFT OUTER JOIN user user ON user.id = api_mt.user_id LEFT OUTER JOIN type type ON type.id = api_mt.type_id LEFT OUTER JOIN api_mt_send_q api_mt_send_q ON api_mt_send_q.api_mt_id = api_mt.id LEFT OUTER JOIN dlr_status dlr_status ON dlr_status.id = api_mt_send_q.dlr_status_id LEFT OUTER JOIN send_status send_status ON send_status.id = api_mt_send_q.send_status_id WHERE api_mt.is_in_trash=0 OR api_mt.is_in_trash IS NULL) AS `t1` LIMIT 100000 OFFSET 0
[2018-04-18T10:59:19,292][WARN ][logstash.agent           ] stopping pipeline {:id=>"main"}
[2018-04-18T15:36:00,516][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/home/kurt/migrations/jdbc-importer/logstash/logstash-5.6.0/modules/netflow/configuration"}
[2018-04-18T15:36:00,540][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/home/kurt/migrations/jdbc-importer/logstash/logstash-5.6.0/modules/fb_apache/configuration"}
[2018-04-18T15:36:02,657][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://localhost:9200/]}}
[2018-04-18T15:36:02,659][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://localhost:9200/, :path=>"/"}
[2018-04-18T15:36:02,954][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://localhost:9200/"}
[2018-04-18T15:36:02,959][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-04-18T15:36:03,055][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-04-18T15:36:03,098][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//localhost:9200"]}
[2018-04-18T15:36:03,101][INFO ][logstash.pipeline        ] Starting pipeline {"id"=>"main", "pipeline.workers"=>4, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>5, "pipeline.max_inflight"=>500}
[2018-04-18T15:36:03,629][INFO ][logstash.pipeline        ] Pipeline main started
[2018-04-18T15:36:03,887][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2018-04-18T15:36:05,559][INFO ][logstash.inputs.jdbc     ] (0.061000s) SELECT count(*) AS `count` FROM (SELECT `campaign`.`is_in_trash`, `campaign`.`id`, `campaign`.`message`, `campaign`.`name`, `campaign`.`campaign_status_id`, `campaign`.`keyword_id`, `campaign`.`is_valid`, `creator_user`.fname creator_fname, `creator_user`.mname creator_mname, `creator_user`.lname creator_lname, `updater_user`.fname updater_fname, `updater_user`.mname updater_mname, `updater_user`.lname updater_lname, `campaign`.date_created, `campaign`.date_completed, `campaign`.account_id, `campaign`.`campaign_type_id`, `campaign_type`.name campaign_type, `campaign_status`.name campaign_status_name FROM (`campaign`) LEFT OUTER JOIN `user` creator_user ON `creator_user`.`id` = `campaign`.`created_by_id` LEFT OUTER JOIN `user` updater_user ON `updater_user`.`id` = `campaign`.`updated_by_id` LEFT OUTER JOIN `campaign_type` campaign_type ON `campaign_type`.`id` = `campaign`.`campaign_type_id` LEFT OUTER JOIN `campaign_status` campaign_status ON `campaign_status`.`id` = `campaign`.`campaign_status_id`) AS `t1` LIMIT 1
[2018-04-18T15:36:05,672][INFO ][logstash.inputs.jdbc     ] (0.074000s) SELECT * FROM (SELECT `campaign`.`is_in_trash`, `campaign`.`id`, `campaign`.`message`, `campaign`.`name`, `campaign`.`campaign_status_id`, `campaign`.`keyword_id`, `campaign`.`is_valid`, `creator_user`.fname creator_fname, `creator_user`.mname creator_mname, `creator_user`.lname creator_lname, `updater_user`.fname updater_fname, `updater_user`.mname updater_mname, `updater_user`.lname updater_lname, `campaign`.date_created, `campaign`.date_completed, `campaign`.account_id, `campaign`.`campaign_type_id`, `campaign_type`.name campaign_type, `campaign_status`.name campaign_status_name FROM (`campaign`) LEFT OUTER JOIN `user` creator_user ON `creator_user`.`id` = `campaign`.`created_by_id` LEFT OUTER JOIN `user` updater_user ON `updater_user`.`id` = `campaign`.`updated_by_id` LEFT OUTER JOIN `campaign_type` campaign_type ON `campaign_type`.`id` = `campaign`.`campaign_type_id` LEFT OUTER JOIN `campaign_status` campaign_status ON `campaign_status`.`id` = `campaign`.`campaign_status_id`) AS `t1` LIMIT 100000 OFFSET 0
[2018-04-18T15:36:08,212][WARN ][logstash.agent           ] stopping pipeline {:id=>"main"}
[2018-04-18T15:37:17,697][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"netflow", :directory=>"/home/kurt/migrations/jdbc-importer/logstash/logstash-5.6.0/modules/netflow/configuration"}
[2018-04-18T15:37:17,702][INFO ][logstash.modules.scaffold] Initializing module {:module_name=>"fb_apache", :directory=>"/home/kurt/migrations/jdbc-importer/logstash/logstash-5.6.0/modules/fb_apache/configuration"}
[2018-04-18T15:37:18,253][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://localhost:9200/]}}
[2018-04-18T15:37:18,254][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=>http://localhost:9200/, :path=>"/"}
[2018-04-18T15:37:18,349][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>"http://localhost:9200/"}
[2018-04-18T15:37:18,350][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}
[2018-04-18T15:37:18,400][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{"template"=>"logstash-*", "version"=>60001, "settings"=>{"index.refresh_interval"=>"5s"}, "mappings"=>{"_default_"=>{"dynamic_templates"=>[{"message_field"=>{"path_match"=>"message", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false}}}, {"string_fields"=>{"match"=>"*", "match_mapping_type"=>"string", "mapping"=>{"type"=>"text", "norms"=>false, "fields"=>{"keyword"=>{"type"=>"keyword", "ignore_above"=>256}}}}}], "properties"=>{"@timestamp"=>{"type"=>"date"}, "@version"=>{"type"=>"keyword"}, "geoip"=>{"dynamic"=>true, "properties"=>{"ip"=>{"type"=>"ip"}, "location"=>{"type"=>"geo_point"}, "latitude"=>{"type"=>"half_float"}, "longitude"=>{"type"=>"half_float"}}}}}}}}
[2018-04-18T15:37:18,411][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["//localhost:9200"]}
[2018-04-18T15:37:18,414][INFO ][logstash.pipeline        ] Starting pipeline {"id"=>"main", "pipeline.workers"=>4, "pipeline.batch.size"=>125, "pipeline.batch.delay"=>5, "pipeline.max_inflight"=>500}
[2018-04-18T15:37:18,567][INFO ][logstash.pipeline        ] Pipeline main started
[2018-04-18T15:37:18,644][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2018-04-18T15:37:19,254][INFO ][logstash.inputs.jdbc     ] (0.032000s) SELECT count(*) AS `count` FROM (SELECT `campaign`.`is_in_trash`, `campaign`.`id`, `campaign`.`message`, `campaign`.`name`, `campaign`.`campaign_status_id`, `campaign`.`keyword_id`, `campaign`.`is_valid`, `creator_user`.fname creator_fname, `creator_user`.mname creator_mname, `creator_user`.lname creator_lname, `updater_user`.fname updater_fname, `updater_user`.mname updater_mname, `updater_user`.lname updater_lname, `campaign`.date_created, `campaign`.date_completed, `campaign`.account_id, `campaign`.`campaign_type_id`, `campaign_type`.name campaign_type, `campaign_status`.name campaign_status_name FROM (`campaign`) LEFT OUTER JOIN `user` creator_user ON `creator_user`.`id` = `campaign`.`created_by_id` LEFT OUTER JOIN `user` updater_user ON `updater_user`.`id` = `campaign`.`updated_by_id` LEFT OUTER JOIN `campaign_type` campaign_type ON `campaign_type`.`id` = `campaign`.`campaign_type_id` LEFT OUTER JOIN `campaign_status` campaign_status ON `campaign_status`.`id` = `campaign`.`campaign_status_id`) AS `t1` LIMIT 1
[2018-04-18T15:37:19,298][INFO ][logstash.inputs.jdbc     ] (0.040000s) SELECT * FROM (SELECT `campaign`.`is_in_trash`, `campaign`.`id`, `campaign`.`message`, `campaign`.`name`, `campaign`.`campaign_status_id`, `campaign`.`keyword_id`, `campaign`.`is_valid`, `creator_user`.fname creator_fname, `creator_user`.mname creator_mname, `creator_user`.lname creator_lname, `updater_user`.fname updater_fname, `updater_user`.mname updater_mname, `updater_user`.lname updater_lname, `campaign`.date_created, `campaign`.date_completed, `campaign`.account_id, `campaign`.`campaign_type_id`, `campaign_type`.name campaign_type, `campaign_status`.name campaign_status_name FROM (`campaign`) LEFT OUTER JOIN `user` creator_user ON `creator_user`.`id` = `campaign`.`created_by_id` LEFT OUTER JOIN `user` updater_user ON `updater_user`.`id` = `campaign`.`updated_by_id` LEFT OUTER JOIN `campaign_type` campaign_type ON `campaign_type`.`id` = `campaign`.`campaign_type_id` LEFT OUTER JOIN `campaign_status` campaign_status ON `campaign_status`.`id` = `campaign`.`campaign_status_id`) AS `t1` LIMIT 100000 OFFSET 0
[2018-04-18T15:37:21,581][WARN ][logstash.agent           ] stopping pipeline {:id=>"main"}
